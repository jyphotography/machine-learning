{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a59d7f1-3e7f-47bb-a0be-6ba7ff297ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:22:12.787461Z",
     "iopub.status.busy": "2024-12-03T21:22:12.787061Z",
     "iopub.status.idle": "2024-12-03T21:22:19.024169Z",
     "shell.execute_reply": "2024-12-03T21:22:19.023544Z",
     "shell.execute_reply.started": "2024-12-03T21:22:12.787433Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:22:13.247977: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 21:22:13.250427: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-03 21:22:13.294438: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-03 21:22:13.295200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 21:22:15.945965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448eaf1-1ce9-4ce1-9f79-dc52090d58bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:23:36.059238Z",
     "iopub.status.busy": "2024-12-03T21:23:36.058340Z",
     "iopub.status.idle": "2024-12-03T21:23:36.063933Z",
     "shell.execute_reply": "2024-12-03T21:23:36.062895Z",
     "shell.execute_reply.started": "2024-12-03T21:23:36.059205Z"
    },
    "tags": []
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 1000 images of hairs in the separate folders \n",
    "for training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02da643d-0682-4391-af06-bf622bd6dc2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:24:45.816762Z",
     "iopub.status.busy": "2024-12-03T21:24:45.816381Z",
     "iopub.status.idle": "2024-12-03T21:24:46.968657Z",
     "shell.execute_reply": "2024-12-03T21:24:46.967901Z",
     "shell.execute_reply.started": "2024-12-03T21:24:45.816733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81cdf907-70c1-4ea7-afc9-6434d236f641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:24:47.770742Z",
     "iopub.status.busy": "2024-12-03T21:24:47.769966Z",
     "iopub.status.idle": "2024-12-03T21:24:47.774447Z",
     "shell.execute_reply": "2024-12-03T21:24:47.773680Z",
     "shell.execute_reply.started": "2024-12-03T21:24:47.770711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8e3857-d45b-4697-9910-91e9000bd799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:24:53.990306Z",
     "iopub.status.busy": "2024-12-03T21:24:53.989906Z",
     "iopub.status.idle": "2024-12-03T21:24:54.031543Z",
     "shell.execute_reply": "2024-12-03T21:24:54.030838Z",
     "shell.execute_reply.started": "2024-12-03T21:24:53.990281Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d442a85a-786f-43aa-b5c0-3d342650f23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:26:30.661189Z",
     "iopub.status.busy": "2024-12-03T21:26:30.660796Z",
     "iopub.status.idle": "2024-12-03T21:26:30.665742Z",
     "shell.execute_reply": "2024-12-03T21:26:30.665064Z",
     "shell.execute_reply.started": "2024-12-03T21:26:30.661165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d66df9-7fa8-4abc-a0ec-05423cfe98ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:27:34.209236Z",
     "iopub.status.busy": "2024-12-03T21:27:34.208835Z",
     "iopub.status.idle": "2024-12-03T21:27:34.212808Z",
     "shell.execute_reply": "2024-12-03T21:27:34.212199Z",
     "shell.execute_reply.started": "2024-12-03T21:27:34.209211Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657d2cc1-e362-46bf-8404-a76beb5b87c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:35:44.483541Z",
     "iopub.status.busy": "2024-12-03T21:35:44.483128Z",
     "iopub.status.idle": "2024-12-03T21:35:44.487267Z",
     "shell.execute_reply": "2024-12-03T21:35:44.486338Z",
     "shell.execute_reply.started": "2024-12-03T21:35:44.483515Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127ef0f-4fb9-48fd-94eb-e1817d96c9e2",
   "metadata": {},
   "source": [
    "For this will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(200, 200, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b9e9a0-bb6a-4f5e-a7b6-31eae7b65faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:41:14.007800Z",
     "iopub.status.busy": "2024-12-03T21:41:14.007392Z",
     "iopub.status.idle": "2024-12-03T21:41:14.011411Z",
     "shell.execute_reply": "2024-12-03T21:41:14.010599Z",
     "shell.execute_reply.started": "2024-12-03T21:41:14.007777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = './data/test/curly'\n",
    "name = '03312ac556a7d003f7570657f80392c34.jpg'\n",
    "fullname = f'{path}/{name}'\n",
    "# load_img(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b48c41-ba8f-42db-a616-43333bace65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:42:06.823186Z",
     "iopub.status.busy": "2024-12-03T21:42:06.822753Z",
     "iopub.status.idle": "2024-12-03T21:42:06.837971Z",
     "shell.execute_reply": "2024-12-03T21:42:06.837213Z",
     "shell.execute_reply.started": "2024-12-03T21:42:06.823154Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(fullname, target_size=(200, 200))\n",
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6ccd8-2d76-46f4-8862-5491362a55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905b69a-bd17-488b-9215-3e0a83824f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9e818-beb2-4f4b-959c-b42480b90963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7acb7f06-660f-40c1-ab8b-91ff4c5a952b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:50:09.276924Z",
     "iopub.status.busy": "2024-12-03T21:50:09.276535Z",
     "iopub.status.idle": "2024-12-03T21:50:09.282767Z",
     "shell.execute_reply": "2024-12-03T21:50:09.281906Z",
     "shell.execute_reply.started": "2024-12-03T21:50:09.276896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd6da9b-cb10-474e-a711-63c0bc296d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:50:30.652209Z",
     "iopub.status.busy": "2024-12-03T21:50:30.651808Z",
     "iopub.status.idle": "2024-12-03T21:50:30.815528Z",
     "shell.execute_reply": "2024-12-03T21:50:30.814660Z",
     "shell.execute_reply.started": "2024-12-03T21:50:30.652185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 99, 99, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 313632)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                20072512  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20073473 (76.57 MB)\n",
      "Trainable params: 20073473 (76.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the multi-dimensional result into vectors\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 64 neurons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 neuron for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with SGD optimizer\n",
    "optimizer = SGD(lr=0.002, momentum=0.8)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a367b214-7e65-4e2e-8e67-9d235278501a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:52:48.448772Z",
     "iopub.status.busy": "2024-12-03T21:52:48.448379Z",
     "iopub.status.idle": "2024-12-03T21:52:48.498975Z",
     "shell.execute_reply": "2024-12-03T21:52:48.498407Z",
     "shell.execute_reply.started": "2024-12-03T21:52:48.448750Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     vertical_flip=True,\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eddfecf3-c8cb-462a-8ee7-0bdd0c74942d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:56:52.358640Z",
     "iopub.status.busy": "2024-12-03T21:56:52.358255Z",
     "iopub.status.idle": "2024-12-03T21:56:52.362197Z",
     "shell.execute_reply": "2024-12-03T21:56:52.361355Z",
     "shell.execute_reply.started": "2024-12-03T21:56:52.358612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a061644-a9be-4239-abb9-36ebfb819a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T21:56:54.375294Z",
     "iopub.status.busy": "2024-12-03T21:56:54.374863Z",
     "iopub.status.idle": "2024-12-03T21:56:54.422975Z",
     "shell.execute_reply": "2024-12-03T21:56:54.421807Z",
     "shell.execute_reply.started": "2024-12-03T21:56:54.375264Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/keras/src/preprocessing/image.py:2525\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.preprocessing.image.apply_affine_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_affine_transform\u001b[39m(\n\u001b[1;32m   2483\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2495\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   2496\u001b[0m ):\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies an affine transformation specified by the parameters given.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;124;03m        ImportError: if SciPy is not available.\u001b[39;00m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscipy\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage transformations require SciPy. Install SciPy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;66;03m# Input sanity checks:\u001b[39;00m\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     \u001b[38;5;66;03m# 2. channels must be either first or last dimension\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
